{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxwlue6GMg8R06opEn3Oez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameekshya1999/Sleep-Stage-Classification-Using-Deep-Learning-CNN-vs.-EEGNet-Attention-/blob/main/EEGnet%2Btemporal%26CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7DqDh61FMb4",
        "outputId": "c0dc9f62-747b-4d44-d8ff-6c381e15b3d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy tensorflow keras mne urllib3 scikit-learn tqdm matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import mne\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import gc\n",
        "\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "mne.set_log_level('ERROR')\n",
        "\n",
        "NUM_SUBJECTS = 20\n",
        "NUM_NIGHTS = 2\n",
        "BASE_URL = \"https://physionet.org/files/sleep-edfx/1.0.0/\"\n",
        "TARGET_CHANNELS = ['EEG Fpz-Cz', 'EEG Pz-Oz']\n",
        "EPOCH_DURATION = 30\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "SAMPLING_RATE = 50\n",
        "\n",
        "TELEMETRY_SUBJECTS = [2, 4, 5, 6, 7, 12, 13]\n",
        "\n",
        "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
        "\n",
        "def fetch_data(subject_id, night, record_type='PSG'):\n",
        "    try:\n",
        "        dataset_id = subject_id + 1\n",
        "        folder = \"sleep-cassette\" if night == 1 else \"sleep-telemetry\"\n",
        "\n",
        "        if night == 1:\n",
        "            prefix = f\"SC4{dataset_id:02d}\"\n",
        "        else:\n",
        "            if subject_id not in TELEMETRY_SUBJECTS:\n",
        "                return None\n",
        "            telemetry_map = {2: 702, 4: 704, 5: 705, 6: 706, 7: 707, 12: 712, 13: 713}\n",
        "            prefix = f\"ST{telemetry_map.get(subject_id, 700 + dataset_id)}\"\n",
        "\n",
        "        file_name = f\"{prefix}{night if night == 1 else 2}E0-PSG.edf\" if record_type == 'PSG' else \\\n",
        "                    f\"{prefix}{night if night == 1 else 2}EC-Hypnogram.edf\"\n",
        "        url = f\"{BASE_URL}{folder}/{file_name}\"\n",
        "        local_file = os.path.join(\"sleep_edf\", file_name)\n",
        "        os.makedirs(\"sleep_edf\", exist_ok=True)\n",
        "\n",
        "        if not os.path.exists(local_file):\n",
        "            urllib.request.urlretrieve(url, local_file)\n",
        "            print(f\"Downloaded {file_name}\")\n",
        "        return local_file\n",
        "    except urllib.error.HTTPError as e:\n",
        "        print(f\"HTTP Error {e.code} fetching {file_name}: {e.reason}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {file_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_available_subjects():\n",
        "    available = []\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = []\n",
        "        for subject_id in range(NUM_SUBJECTS):\n",
        "            for night in range(1, NUM_NIGHTS + 1):\n",
        "                futures.append((\n",
        "                    subject_id,\n",
        "                    night,\n",
        "                    executor.submit(\n",
        "                        lambda s, n: (\n",
        "                            fetch_data(s, n, 'PSG') is not None and\n",
        "                            fetch_data(s, n, 'Hypnogram') is not None\n",
        "                        ),\n",
        "                        subject_id, night\n",
        "                    )\n",
        "                ))\n",
        "\n",
        "        for subject_id, night, future in tqdm(futures, desc=\"Checking availability\"):\n",
        "            if future.result():\n",
        "                available.append((subject_id, night))\n",
        "    print(f\"Available subject-night pairs: {available}\")\n",
        "    return available\n",
        "\n",
        "def augment_data(X):\n",
        "    noise = np.random.normal(0, 0.01, X.shape)\n",
        "    shift = np.random.randint(-50, 50)\n",
        "    X_aug = np.roll(X + noise, shift, axis=1)\n",
        "    return X_aug\n",
        "\n",
        "def process_subject_night(subject_id, night):\n",
        "    try:\n",
        "        psg_file = fetch_data(subject_id, night, 'PSG')\n",
        "        hypno_file = fetch_data(subject_id, night, 'Hypnogram')\n",
        "        if psg_file is None or hypno_file is None:\n",
        "            print(f\"Skipping subject {subject_id}, night {night}: Missing files\")\n",
        "            return None, None\n",
        "\n",
        "        raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
        "        available_channels = [ch for ch in TARGET_CHANNELS if ch in raw.ch_names]\n",
        "        if not available_channels:\n",
        "            print(f\"No target channels for subject {subject_id}, night {night}\")\n",
        "            return None, None\n",
        "        raw.pick_channels(available_channels)\n",
        "\n",
        "        raw.load_data()\n",
        "        raw.filter(0.5, 40.0, l_trans_bandwidth=0.5, h_trans_bandwidth=10.0, verbose=False)\n",
        "        raw.resample(SAMPLING_RATE, npad=\"auto\")\n",
        "\n",
        "        events = mne.make_fixed_length_events(raw, id=1, duration=EPOCH_DURATION)\n",
        "        epochs_mne = mne.Epochs(raw, events, tmin=0, tmax=EPOCH_DURATION-1/raw.info['sfreq'],\n",
        "                                picks=available_channels, baseline=None, preload=True)\n",
        "        data = epochs_mne.get_data(units='uV')\n",
        "\n",
        "        annotations = mne.read_annotations(hypno_file)\n",
        "        labels = np.zeros(len(epochs_mne), dtype=int)\n",
        "        stage_map = {\n",
        "            'Sleep stage W': 0,\n",
        "            'Sleep stage 1': 1,\n",
        "            'Sleep stage 2': 2,\n",
        "            'Sleep stage 3': 3,\n",
        "            'Sleep stage 4': 3,\n",
        "            'Sleep stage R': 4\n",
        "        }\n",
        "\n",
        "        for annot in annotations:\n",
        "            onset = int(annot['onset'] / EPOCH_DURATION)\n",
        "            duration = int(annot['duration'] / EPOCH_DURATION)\n",
        "            stage = annot['description']\n",
        "            if stage in stage_map:\n",
        "                for i in range(max(0, onset), min(len(epochs_mne), onset + duration)):\n",
        "                    labels[i] = stage_map[stage]\n",
        "\n",
        "        data = (\n",
        "            (data - np.mean(data, axis=(1, 2), keepdims=True)) /\n",
        "            np.std(data, axis=(1, 2), keepdims=True)\n",
        "        )\n",
        "        X = data.transpose(0, 2, 1)\n",
        "        X_aug = augment_data(X)\n",
        "        X = np.concatenate([X, X_aug])\n",
        "        labels = np.concatenate([labels, labels])\n",
        "\n",
        "        del raw, epochs_mne, data\n",
        "        gc.collect()\n",
        "\n",
        "        print(f\"Processed subject {subject_id}, night {night}: {X.shape[0]} epochs\")\n",
        "        return X, labels\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing subject {subject_id}, night {night}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "class EEGDataGenerator(Sequence):\n",
        "    def __init__(self, X, y, batch_size, augment=True, class_weights=None):\n",
        "        self.X = X.astype(np.float32)\n",
        "        self.y = y.astype(np.int32)\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augment\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.batch_size\n",
        "        end = min(start + self.batch_size, len(self.X))\n",
        "        X_batch = self.X[start:end]\n",
        "        y_batch = self.y[start:end]\n",
        "\n",
        "        if self.augment:\n",
        "            X_batch = augment_data(X_batch).astype(np.float32)\n",
        "\n",
        "        sample_weights = np.ones_like(y_batch, dtype=np.float32)\n",
        "        if self.class_weights:\n",
        "            sample_weights = np.array([self.class_weights[label] for label in y_batch], dtype=np.float32)\n",
        "\n",
        "        return X_batch, y_batch, sample_weights\n",
        "\n",
        "class TemporalAttention(layers.Layer):\n",
        "    def __init__(self, heads=4, key_dim=24):\n",
        "        super().__init__()\n",
        "        self.multi_head = layers.MultiHeadAttention(num_heads=heads, key_dim=key_dim)\n",
        "        self.norm = layers.LayerNormalization()\n",
        "        self.add = layers.Add()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn_output = self.multi_head(inputs, inputs)\n",
        "        out = self.add([inputs, attn_output])\n",
        "        return self.norm(out)\n",
        "\n",
        "def build_cnn_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv1D(64, 7, padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv1D(128, 5, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv1D(256, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Fully connected\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_eegnet_attention(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv1D(64, 7, padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv1D(128, 7, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Temporal Attention\n",
        "    x = TemporalAttention(heads=4, key_dim=24)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Output\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def plot_training_curves(history, model_name):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'{model_name} - Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{model_name} - Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'training_curves_{model_name}.png')\n",
        "    plt.close()\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\n{model_name} - Test Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"{model_name} - Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    y_pred = model.predict(X_test, verbose=0)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_classes, average=None)\n",
        "    stage_names = ['Wake', 'N1', 'N2', 'N3', 'REM']\n",
        "    print(f\"\\n{model_name} - Per-class Metrics:\")\n",
        "    for i, stage in enumerate(stage_names):\n",
        "        print(f\"{stage}: Precision={precision[i]:.4f}, Recall={recall[i]:.4f}, F1={f1[i]:.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=stage_names, yticklabels=stage_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.savefig(f'confusion_matrix_{model_name}.png')\n",
        "    plt.close()\n",
        "\n",
        "def data_generator(available, batch_size=2000):\n",
        "    for subject_id, night in available:\n",
        "        X, y = process_subject_night(subject_id, night)\n",
        "        if X is None or y is None:\n",
        "            continue\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            yield X[i:i+batch_size], y[i:i+batch_size]\n",
        "        del X, y\n",
        "        gc.collect()\n",
        "\n",
        "def run_pipeline():\n",
        "    available = get_available_subjects()\n",
        "    if not available:\n",
        "        return\n",
        "\n",
        "    X_train, y_train, X_test, y_test = [], [], [], []\n",
        "    for X_batch, y_batch in tqdm(data_generator(available), desc=\"Processing data\"):\n",
        "        if X_batch is None or y_batch is None:\n",
        "            continue\n",
        "        class_counts = np.bincount(y_batch)\n",
        "        stratify = y_batch if min(class_counts[class_counts > 0]) >= 2 else None\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X_batch, y_batch, test_size=0.2, stratify=stratify, random_state=42)\n",
        "        X_train.append(X_tr); y_train.append(y_tr)\n",
        "        X_test.append(X_te); y_test.append(y_te)\n",
        "        del X_batch, y_batch\n",
        "        gc.collect()\n",
        "\n",
        "    if not X_train:\n",
        "        return\n",
        "\n",
        "    X_train = np.concatenate(X_train)\n",
        "    y_train = np.concatenate(y_train)\n",
        "    X_test = np.concatenate(X_test)\n",
        "    y_test = np.concatenate(y_test)\n",
        "\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    # Train and evaluate CNN model\n",
        "    print(\"\\nTraining CNN model...\")\n",
        "    cnn_model = build_cnn_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
        "    train_generator = EEGDataGenerator(X_train, y_train, BATCH_SIZE, augment=True, class_weights=class_weight_dict)\n",
        "    val_generator = EEGDataGenerator(X_test, y_test, BATCH_SIZE, augment=False, class_weights=class_weight_dict)\n",
        "    cnn_history = cnn_model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS, verbose=1)\n",
        "    plot_training_curves(cnn_history, \"CNN\")\n",
        "    evaluate_model(cnn_model, X_test, y_test, \"CNN\")\n",
        "\n",
        "    # Train and evaluate EEGNet+Attention model\n",
        "    print(\"\\nTraining EEGNet+Attention model...\")\n",
        "    eegnet_model = build_eegnet_attention(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
        "    eegnet_history = eegnet_model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS, verbose=1)\n",
        "    plot_training_curves(eegnet_history, \"EEGNet_Attention\")\n",
        "    evaluate_model(eegnet_model, X_test, y_test, \"EEGNet_Attention\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_pipeline()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfFRPcZjFYXv",
        "outputId": "2a8acf02-6dc9-45f8-d6a3-6b9457c04387"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn version: 1.6.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking availability:   2%|▎         | 1/40 [00:00<00:31,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP Error 404 fetching ST7042E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching ST7122E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching ST7052E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching SC4011EC-Hypnogram.edf: Not Found\n",
            "HTTP Error 404 fetching SC4141EC-Hypnogram.edf: Not Found\n",
            "HTTP Error 404 fetching ST7132E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching ST7072E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching ST7062E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching ST7022E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching SC4021EC-Hypnogram.edf: Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking availability: 100%|██████████| 40/40 [00:01<00:00, 25.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP Error 404 fetching SC4171EC-Hypnogram.edf: Not Found\n",
            "HTTP Error 404 fetching SC4191EC-Hypnogram.edf: Not Found\n",
            "Available subject-night pairs: [(2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (14, 1), (15, 1), (17, 1), (19, 1)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing data: 0it [00:00, ?it/s]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 2, night 1: 5640 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 3it [00:05,  1.22s/it]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 3, night 1: 5140 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 6it [00:08,  1.02s/it]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 4, night 1: 5444 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 9it [00:12,  1.00it/s]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 5, night 1: 5540 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 12it [00:16,  1.01it/s]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 6, night 1: 5620 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 15it [00:22,  1.17s/it]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 7, night 1: 5592 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 18it [00:26,  1.06s/it]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 8, night 1: 5464 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 21it [00:30,  1.00s/it]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 9, night 1: 5440 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 24it [00:34,  1.01it/s]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 10, night 1: 5284 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 27it [00:38,  1.02it/s]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 11, night 1: 5572 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 30it [00:42,  1.02it/s]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 12, night 1: 5628 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 33it [00:47,  1.16s/it]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 14, night 1: 5240 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 36it [00:51,  1.03s/it]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 15, night 1: 5252 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 39it [00:55,  1.02it/s]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 17, night 1: 5512 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 42it [00:59,  1.01it/s]/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-3-3446416530.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 19, night 1: 5608 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 45it [01:04,  1.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training CNN model...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m511/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5959 - loss: 1.8943"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.5965 - loss: 1.8908 - val_accuracy: 0.7820 - val_loss: 0.8888\n",
            "Epoch 2/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7706 - loss: 0.9301 - val_accuracy: 0.8779 - val_loss: 1.0254\n",
            "Epoch 3/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.7974 - loss: 0.8549 - val_accuracy: 0.8407 - val_loss: 0.7023\n",
            "Epoch 4/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8328 - loss: 0.7341 - val_accuracy: 0.8034 - val_loss: 0.6969\n",
            "Epoch 5/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8352 - loss: 0.6767 - val_accuracy: 0.8649 - val_loss: 0.7225\n",
            "Epoch 6/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8527 - loss: 0.6210 - val_accuracy: 0.8050 - val_loss: 0.6850\n",
            "Epoch 7/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8497 - loss: 0.6348 - val_accuracy: 0.8362 - val_loss: 0.6355\n",
            "Epoch 8/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8566 - loss: 0.6188 - val_accuracy: 0.8850 - val_loss: 0.6837\n",
            "Epoch 9/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8636 - loss: 0.6439 - val_accuracy: 0.8840 - val_loss: 0.6216\n",
            "Epoch 10/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8664 - loss: 0.6176 - val_accuracy: 0.8630 - val_loss: 0.6177\n",
            "Epoch 11/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8835 - loss: 0.5602 - val_accuracy: 0.8927 - val_loss: 0.6101\n",
            "Epoch 12/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8919 - loss: 0.5666 - val_accuracy: 0.8826 - val_loss: 0.5625\n",
            "Epoch 13/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8933 - loss: 0.5452 - val_accuracy: 0.8862 - val_loss: 0.5970\n",
            "Epoch 14/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8965 - loss: 0.5185 - val_accuracy: 0.8690 - val_loss: 0.6288\n",
            "Epoch 15/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9031 - loss: 0.4789 - val_accuracy: 0.8970 - val_loss: 0.4926\n",
            "Epoch 16/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8998 - loss: 0.4625 - val_accuracy: 0.8988 - val_loss: 0.7544\n",
            "Epoch 17/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8997 - loss: 0.4443 - val_accuracy: 0.9035 - val_loss: 0.4657\n",
            "Epoch 18/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9125 - loss: 0.4255 - val_accuracy: 0.8865 - val_loss: 0.5675\n",
            "Epoch 19/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9107 - loss: 0.4094 - val_accuracy: 0.8905 - val_loss: 0.4632\n",
            "Epoch 20/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9191 - loss: 0.3863 - val_accuracy: 0.8818 - val_loss: 0.4535\n",
            "\n",
            "CNN - Test Accuracy: 0.8818\n",
            "CNN - Test Loss: 0.2969\n",
            "\n",
            "CNN - Per-class Metrics:\n",
            "Wake: Precision=0.9992, Recall=0.9335, F1=0.9652\n",
            "N1: Precision=0.2375, Recall=0.7807, F1=0.3643\n",
            "N2: Precision=0.9530, Recall=0.6756, F1=0.7907\n",
            "N3: Precision=0.6186, Recall=0.9797, F1=0.7583\n",
            "REM: Precision=0.6492, Recall=0.8150, F1=0.7227\n",
            "\n",
            "Training EEGNet+Attention model...\n",
            "Epoch 1/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 43ms/step - accuracy: 0.7466 - loss: 0.8087 - val_accuracy: 0.8294 - val_loss: 0.5928\n",
            "Epoch 2/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.8933 - loss: 0.4668 - val_accuracy: 0.8754 - val_loss: 0.4762\n",
            "Epoch 3/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.9013 - loss: 0.4326 - val_accuracy: 0.8980 - val_loss: 0.4196\n",
            "Epoch 4/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9159 - loss: 0.3715 - val_accuracy: 0.9136 - val_loss: 0.4456\n",
            "Epoch 5/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9137 - loss: 0.3814 - val_accuracy: 0.9037 - val_loss: 0.4177\n",
            "Epoch 6/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9204 - loss: 0.3561 - val_accuracy: 0.9201 - val_loss: 0.4143\n",
            "Epoch 7/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 32ms/step - accuracy: 0.9230 - loss: 0.3398 - val_accuracy: 0.9088 - val_loss: 0.4155\n",
            "Epoch 8/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 32ms/step - accuracy: 0.9243 - loss: 0.3258 - val_accuracy: 0.9215 - val_loss: 0.3722\n",
            "Epoch 9/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 32ms/step - accuracy: 0.9290 - loss: 0.3066 - val_accuracy: 0.8716 - val_loss: 0.4410\n",
            "Epoch 10/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9262 - loss: 0.3157 - val_accuracy: 0.9274 - val_loss: 0.3991\n",
            "Epoch 11/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9340 - loss: 0.2815 - val_accuracy: 0.9223 - val_loss: 0.3883\n",
            "Epoch 12/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9363 - loss: 0.2672 - val_accuracy: 0.9187 - val_loss: 0.3579\n",
            "Epoch 13/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 32ms/step - accuracy: 0.9344 - loss: 0.2533 - val_accuracy: 0.9263 - val_loss: 0.4006\n",
            "Epoch 14/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9366 - loss: 0.2559 - val_accuracy: 0.9206 - val_loss: 0.3711\n",
            "Epoch 15/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9373 - loss: 0.2517 - val_accuracy: 0.9335 - val_loss: 0.3861\n",
            "Epoch 16/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9424 - loss: 0.2309 - val_accuracy: 0.9230 - val_loss: 0.3757\n",
            "Epoch 17/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 32ms/step - accuracy: 0.9449 - loss: 0.2108 - val_accuracy: 0.9340 - val_loss: 0.3224\n",
            "Epoch 18/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 32ms/step - accuracy: 0.9466 - loss: 0.2010 - val_accuracy: 0.9173 - val_loss: 0.3790\n",
            "Epoch 19/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9491 - loss: 0.1909 - val_accuracy: 0.9171 - val_loss: 0.3972\n",
            "Epoch 20/20\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9436 - loss: 0.2095 - val_accuracy: 0.9331 - val_loss: 0.3759\n",
            "\n",
            "EEGNet_Attention - Test Accuracy: 0.9331\n",
            "EEGNet_Attention - Test Loss: 0.1996\n",
            "\n",
            "EEGNet_Attention - Per-class Metrics:\n",
            "Wake: Precision=0.9992, Recall=0.9688, F1=0.9838\n",
            "N1: Precision=0.3861, Recall=0.8275, F1=0.5265\n",
            "N2: Precision=0.9127, Recall=0.8376, F1=0.8735\n",
            "N3: Precision=0.7913, Recall=0.9522, F1=0.8643\n",
            "REM: Precision=0.8086, Recall=0.8168, F1=0.8127\n"
          ]
        }
      ]
    }
  ]
}