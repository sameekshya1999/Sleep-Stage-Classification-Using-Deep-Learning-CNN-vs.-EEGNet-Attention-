{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPmZMRA02WZEOrNgmzYKXCA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameekshya1999/Sleep-Stage-Classification-Using-Deep-Learning-CNN-vs.-EEGNet-Attention-/blob/main/eegnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFe9wotyxFLK",
        "outputId": "1f36988e-0ca6-4415-b8f5-74a0ccdc2ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy tensorflow keras mne urllib3 scikit-learn tqdm matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import mne\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import gc\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "mne.set_log_level('ERROR')\n",
        "\n",
        "NUM_SUBJECTS = 20\n",
        "NUM_NIGHTS = 2\n",
        "BASE_URL = \"https://physionet.org/files/sleep-edfx/1.0.0/\"\n",
        "TARGET_CHANNELS = ['EEG Fpz-Cz', 'EEG Pz-Oz']\n",
        "EPOCH_DURATION = 30\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 50\n",
        "SAMPLING_RATE = 50\n",
        "F1 = 8  # Number of temporal filters\n",
        "D = 2   # Depth multiplier for depthwise convolution\n",
        "F2 = 16 # Number of pointwise filters\n",
        "\n",
        "TELEMETRY_SUBJECTS = [2, 4, 5, 6, 7, 12, 13]\n",
        "\n",
        "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
        "\n",
        "def fetch_data(subject_id, night, record_type='PSG'):\n",
        "    try:\n",
        "        dataset_id = subject_id + 1\n",
        "        folder = \"sleep-cassette\" if night == 1 else \"sleep-telemetry\"\n",
        "\n",
        "        if night == 1:\n",
        "            prefix = f\"SC4{dataset_id:02d}\"\n",
        "        else:\n",
        "            if subject_id not in TELEMETRY_SUBJECTS:\n",
        "                return None\n",
        "            telemetry_map = {2: 702, 4: 704, 5: 705, 6: 706, 7: 707, 12: 712, 13: 713}\n",
        "            prefix = f\"ST{telemetry_map.get(subject_id, 700 + dataset_id)}\"\n",
        "\n",
        "        file_name = f\"{prefix}{night if night == 1 else 2}E0-PSG.edf\" if record_type == 'PSG' else \\\n",
        "                    f\"{prefix}{night if night == 1 else 2}EC-Hypnogram.edf\"\n",
        "        url = f\"{BASE_URL}{folder}/{file_name}\"\n",
        "        local_file = os.path.join(\"sleep_edf\", file_name)\n",
        "        os.makedirs(\"sleep_edf\", exist_ok=True)\n",
        "\n",
        "        if not os.path.exists(local_file):\n",
        "            urllib.request.urlretrieve(url, local_file)\n",
        "            print(f\"Downloaded {file_name}\")\n",
        "        return local_file\n",
        "    except urllib.error.HTTPError as e:\n",
        "        print(f\"HTTP Error {e.code} fetching {file_name}: {e.reason}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {file_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_available_subjects():\n",
        "    available = []\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = []\n",
        "        for subject_id in range(NUM_SUBJECTS):\n",
        "            for night in range(1, NUM_NIGHTS + 1):\n",
        "                futures.append((\n",
        "                    subject_id,\n",
        "                    night,\n",
        "                    executor.submit(\n",
        "                        lambda s, n: (\n",
        "                            fetch_data(s, n, 'PSG') is not None and\n",
        "                            fetch_data(s, n, 'Hypnogram') is not None\n",
        "                        ),\n",
        "                        subject_id, night\n",
        "                    )\n",
        "                ))\n",
        "\n",
        "        for subject_id, night, future in tqdm(futures, desc=\"Checking availability\"):\n",
        "            if future.result():\n",
        "                available.append((subject_id, night))\n",
        "    print(f\"Available subject-night pairs: {available}\")\n",
        "    return available\n",
        "\n",
        "def augment_data(X):\n",
        "    noise = np.random.normal(0, 0.01, X.shape)\n",
        "    shift = np.random.randint(-50, 50)\n",
        "    X_aug = np.roll(X + noise, shift, axis=1)\n",
        "    return X_aug\n",
        "\n",
        "def process_subject_night(subject_id, night):\n",
        "    try:\n",
        "        psg_file = fetch_data(subject_id, night, 'PSG')\n",
        "        hypno_file = fetch_data(subject_id, night, 'Hypnogram')\n",
        "        if psg_file is None or hypno_file is None:\n",
        "            print(f\"Skipping subject {subject_id}, night {night}: Missing files\")\n",
        "            return None, None\n",
        "\n",
        "        raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
        "        available_channels = [ch for ch in TARGET_CHANNELS if ch in raw.ch_names]\n",
        "        if len(available_channels) != len(TARGET_CHANNELS):\n",
        "            print(f\"Not all target channels found for subject {subject_id}, night {night}\")\n",
        "            return None, None\n",
        "        raw.pick_channels(available_channels)\n",
        "\n",
        "        raw.load_data()\n",
        "        raw.filter(0.5, 40.0, l_trans_bandwidth=0.5, h_trans_bandwidth=10.0, verbose=False)\n",
        "        raw.resample(SAMPLING_RATE, npad=\"auto\")\n",
        "\n",
        "        events = mne.make_fixed_length_events(raw, id=1, duration=EPOCH_DURATION)\n",
        "        epochs_mne = mne.Epochs(raw, events, tmin=0, tmax=EPOCH_DURATION-1/raw.info['sfreq'],\n",
        "                                picks=available_channels, baseline=None, preload=True)\n",
        "        data = epochs_mne.get_data(units='uV')\n",
        "\n",
        "        annotations = mne.read_annotations(hypno_file)\n",
        "        labels = np.zeros(len(epochs_mne), dtype=int)\n",
        "        stage_map = {\n",
        "            'Sleep stage W': 0,\n",
        "            'Sleep stage 1': 1,\n",
        "            'Sleep stage 2': 2,\n",
        "            'Sleep stage 3': 3,\n",
        "            'Sleep stage 4': 3,\n",
        "            'Sleep stage R': 4\n",
        "        }\n",
        "\n",
        "        for annot in annotations:\n",
        "            onset = int(annot['onset'] / EPOCH_DURATION)\n",
        "            duration = int(annot['duration'] / EPOCH_DURATION)\n",
        "            stage = annot['description']\n",
        "            if stage in stage_map:\n",
        "                for i in range(max(0, onset), min(len(epochs_mne), onset + duration)):\n",
        "                    labels[i] = stage_map[stage]\n",
        "\n",
        "        data = (\n",
        "            (data - np.mean(data, axis=(1, 2), keepdims=True)) /\n",
        "            np.std(data, axis=(1, 2), keepdims=True)\n",
        "        )\n",
        "        X = data.transpose(0, 2, 1)\n",
        "        X_aug = augment_data(X)\n",
        "        X = np.concatenate([X, X_aug])\n",
        "        labels = np.concatenate([labels, labels])\n",
        "\n",
        "        del raw, epochs_mne, data\n",
        "        gc.collect()\n",
        "\n",
        "        print(f\"Processed subject {subject_id}, night {night}: {X.shape[0]} epochs\")\n",
        "        return X, labels\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing subject {subject_id}, night {night}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "class EEGDataGenerator(Sequence):\n",
        "    def __init__(self, X, y, batch_size, augment=True, class_weights=None):\n",
        "        self.X = X.astype(np.float32)\n",
        "        self.y = y.astype(np.int32)\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augment\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.batch_size\n",
        "        end = min(start + self.batch_size, len(self.X))\n",
        "        X_batch = self.X[start:end]\n",
        "        y_batch = self.y[start:end]\n",
        "\n",
        "        if self.augment:\n",
        "            X_batch = augment_data(X_batch).astype(np.float32)\n",
        "\n",
        "        sample_weights = np.ones_like(y_batch, dtype=np.float32)\n",
        "        if self.class_weights:\n",
        "            sample_weights = np.array([self.class_weights[label] for label in y_batch], dtype=np.float32)\n",
        "\n",
        "        return X_batch, y_batch, sample_weights\n",
        "\n",
        "class ExpandDimsLayer(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.expand_dims(inputs, axis=-1)\n",
        "\n",
        "def build_eegnet(input_shape, nb_classes=5, F1=8, D=2, F2=16, dropout_rate=0.5):\n",
        "    \"\"\"\n",
        "    Implementation of EEGNet as per Lawhern et al. (2018).\n",
        "    input_shape: (time_steps, channels)\n",
        "    \"\"\"\n",
        "    input_layer = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1: Temporal convolution\n",
        "    expanded_input = ExpandDimsLayer()(input_layer)\n",
        "    block1 = layers.Conv2D(F1, (1, 64), padding='same', use_bias=False)(expanded_input)\n",
        "    block1 = layers.BatchNormalization()(block1)\n",
        "    block1 = layers.DepthwiseConv2D((input_shape[1], 1), depth_multiplier=D, padding='valid',\n",
        "                                    use_bias=False, depthwise_constraint=tf.keras.constraints.max_norm(1.))(block1)\n",
        "    block1 = layers.BatchNormalization()(block1)\n",
        "    block1 = layers.Activation('elu')(block1)\n",
        "    # Corrected pooling to pool across time dimension\n",
        "    block1 = layers.AveragePooling2D((4, 1))(block1)\n",
        "    block1 = layers.Dropout(dropout_rate)(block1)\n",
        "\n",
        "    # Block 2: Separable convolution\n",
        "    block2 = layers.SeparableConv2D(F2, (1, 16), padding='same', use_bias=False)(block1)\n",
        "    block2 = layers.BatchNormalization()(block2)\n",
        "    block2 = layers.Activation('elu')(block2)\n",
        "    # Corrected pooling to pool across time dimension\n",
        "    block2 = layers.AveragePooling2D((8, 1))(block2)\n",
        "    block2 = layers.Dropout(dropout_rate)(block2)\n",
        "\n",
        "    # Output layer\n",
        "    flatten = layers.Flatten()(block2)\n",
        "    output = layers.Dense(nb_classes, activation='softmax',\n",
        "                         kernel_constraint=tf.keras.constraints.max_norm(0.25))(flatten)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def plot_training_curves(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_curves.png')\n",
        "    plt.close()\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    y_pred = model.predict(X_test, verbose=0)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_classes, average=None)\n",
        "    stage_names = ['Wake', 'N1', 'N2', 'N3', 'REM']\n",
        "    print(\"\\nPer-class Metrics:\")\n",
        "    for i, stage in enumerate(stage_names):\n",
        "        print(f\"{stage}: Precision={precision[i]:.4f}, Recall={recall[i]:.4f}, F1={f1[i]:.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=stage_names, yticklabels=stage_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.savefig('confusion_matrix.png')\n",
        "    plt.close()\n",
        "\n",
        "def data_generator(available, batch_size=2000):\n",
        "    for subject_id, night in available:\n",
        "        X, y = process_subject_night(subject_id, night)\n",
        "        if X is None or y is None:\n",
        "            continue\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            yield X[i:i+batch_size], y[i:i+batch_size]\n",
        "        del X, y\n",
        "        gc.collect()\n",
        "\n",
        "def run_pipeline():\n",
        "    available = get_available_subjects()\n",
        "    if not available:\n",
        "        return\n",
        "\n",
        "    X_train, y_train, X_test, y_test = [], [], [], []\n",
        "    for X_batch, y_batch in tqdm(data_generator(available), desc=\"Processing data\"):\n",
        "        if X_batch is None or y_batch is None:\n",
        "            continue\n",
        "        class_counts = np.bincount(y_batch)\n",
        "        stratify = y_batch if min(class_counts[class_counts > 0]) >= 2 else None\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X_batch, y_batch, test_size=0.2, stratify=stratify, random_state=42)\n",
        "        X_train.append(X_tr); y_train.append(y_tr)\n",
        "        X_test.append(X_te); y_test.append(y_te)\n",
        "        del X_batch, y_batch\n",
        "        gc.collect()\n",
        "\n",
        "    if not X_train:\n",
        "        return\n",
        "\n",
        "    X_train = np.concatenate(X_train)\n",
        "    y_train = np.concatenate(y_train)\n",
        "    X_test = np.concatenate(X_test)\n",
        "    y_test = np.concatenate(y_test)\n",
        "\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    model = build_eegnet(input_shape=(X_train.shape[1], X_train.shape[2]), nb_classes=5, F1=F1, D=D, F2=F2)\n",
        "    train_generator = EEGDataGenerator(X_train, y_train, BATCH_SIZE, augment=True, class_weights=class_weight_dict)\n",
        "    val_generator = EEGDataGenerator(X_test, y_test, BATCH_SIZE, augment=False, class_weights=class_weight_dict)\n",
        "\n",
        "    history = model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS, verbose=1)\n",
        "\n",
        "    plot_training_curves(history)\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST3QQgBWxKMx",
        "outputId": "00465b97-d5a3-42c1-ae42-039e61bc4152"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn version: 1.6.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking availability:   2%|▎         | 1/40 [00:00<00:15,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP Error 404 fetching ST7022E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching ST7062E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching ST7122E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching SC4021EC-Hypnogram.edf: Not Found\n",
            "HTTP Error 404 fetching ST7052E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching SC4141EC-Hypnogram.edf: Not Found\n",
            "HTTP Error 404 fetching ST7132E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching SC4011EC-Hypnogram.edf: Not Found\n",
            "HTTP Error 404 fetching ST7072E0-PSG.edf: Not Found\n",
            "HTTP Error 404 fetching ST7042E0-PSG.edf: Not Found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking availability: 100%|██████████| 40/40 [00:00<00:00, 53.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP Error 404 fetching SC4171EC-Hypnogram.edf: Not Found\n",
            "HTTP Error 404 fetching SC4191EC-Hypnogram.edf: Not Found\n",
            "Available subject-night pairs: [(2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (14, 1), (15, 1), (17, 1), (19, 1)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing data: 0it [00:00, ?it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 2, night 1: 5640 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 3it [00:04,  1.10s/it]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 3, night 1: 5140 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 6it [00:08,  1.09it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 4, night 1: 5444 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 9it [00:11,  1.12it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 5, night 1: 5540 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 12it [00:15,  1.10it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 6, night 1: 5620 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 15it [00:20,  1.10s/it]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 7, night 1: 5592 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 18it [00:24,  1.00it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 8, night 1: 5464 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 21it [00:28,  1.03it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 9, night 1: 5440 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 24it [00:32,  1.05it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 10, night 1: 5284 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 27it [00:36,  1.06it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 11, night 1: 5572 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 30it [00:40,  1.04it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 12, night 1: 5628 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 33it [00:45,  1.13s/it]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 14, night 1: 5240 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 36it [00:49,  1.01it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 15, night 1: 5252 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 39it [00:52,  1.05it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 17, night 1: 5512 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 42it [00:56,  1.05it/s]/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-4-4072040450.py:106: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 19, night 1: 5608 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 45it [01:02,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m512/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6218 - loss: 1.3474"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 57ms/step - accuracy: 0.6221 - loss: 1.3469 - val_accuracy: 0.7075 - val_loss: 1.2804\n",
            "Epoch 2/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7397 - loss: 1.0913 - val_accuracy: 0.6852 - val_loss: 1.0064\n",
            "Epoch 3/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7501 - loss: 1.0373 - val_accuracy: 0.7610 - val_loss: 0.9624\n",
            "Epoch 4/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7655 - loss: 1.0001 - val_accuracy: 0.7675 - val_loss: 0.9628\n",
            "Epoch 5/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7727 - loss: 0.9608 - val_accuracy: 0.7878 - val_loss: 0.9292\n",
            "Epoch 6/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7696 - loss: 0.9757 - val_accuracy: 0.7895 - val_loss: 0.9603\n",
            "Epoch 7/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7810 - loss: 0.9268 - val_accuracy: 0.7713 - val_loss: 0.9243\n",
            "Epoch 8/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7771 - loss: 0.9470 - val_accuracy: 0.7883 - val_loss: 0.9351\n",
            "Epoch 9/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7728 - loss: 0.9825 - val_accuracy: 0.8003 - val_loss: 0.9538\n",
            "Epoch 10/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7869 - loss: 0.9281 - val_accuracy: 0.7897 - val_loss: 0.9064\n",
            "Epoch 11/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7737 - loss: 0.9195 - val_accuracy: 0.7970 - val_loss: 0.9210\n",
            "Epoch 12/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7814 - loss: 0.9233 - val_accuracy: 0.8102 - val_loss: 0.9019\n",
            "Epoch 13/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7848 - loss: 0.9124 - val_accuracy: 0.8027 - val_loss: 0.9059\n",
            "Epoch 14/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7833 - loss: 0.9425 - val_accuracy: 0.8002 - val_loss: 0.9191\n",
            "Epoch 15/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7803 - loss: 0.9255 - val_accuracy: 0.8137 - val_loss: 0.9143\n",
            "Epoch 16/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7924 - loss: 0.8972 - val_accuracy: 0.8195 - val_loss: 0.9286\n",
            "Epoch 17/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7901 - loss: 0.8971 - val_accuracy: 0.8103 - val_loss: 0.8780\n",
            "Epoch 18/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7848 - loss: 0.9182 - val_accuracy: 0.8094 - val_loss: 0.9161\n",
            "Epoch 19/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7819 - loss: 0.9324 - val_accuracy: 0.7918 - val_loss: 0.8533\n",
            "Epoch 20/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7923 - loss: 0.8828 - val_accuracy: 0.7807 - val_loss: 0.8698\n",
            "Epoch 21/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7913 - loss: 0.8904 - val_accuracy: 0.8226 - val_loss: 0.8978\n",
            "Epoch 22/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7918 - loss: 0.9063 - val_accuracy: 0.7994 - val_loss: 0.9181\n",
            "Epoch 23/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7870 - loss: 0.8914 - val_accuracy: 0.7908 - val_loss: 0.9065\n",
            "Epoch 24/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 48ms/step - accuracy: 0.7891 - loss: 0.8780 - val_accuracy: 0.7634 - val_loss: 0.9013\n",
            "Epoch 25/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7908 - loss: 0.9004 - val_accuracy: 0.7985 - val_loss: 0.8717\n",
            "Epoch 26/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7952 - loss: 0.8755 - val_accuracy: 0.8113 - val_loss: 0.8588\n",
            "Epoch 27/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7876 - loss: 0.8628 - val_accuracy: 0.8054 - val_loss: 0.8676\n",
            "Epoch 28/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7914 - loss: 0.8866 - val_accuracy: 0.7803 - val_loss: 0.8965\n",
            "Epoch 29/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7965 - loss: 0.8638 - val_accuracy: 0.7930 - val_loss: 0.8559\n",
            "Epoch 30/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7860 - loss: 0.8949 - val_accuracy: 0.7943 - val_loss: 0.8711\n",
            "Epoch 31/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7884 - loss: 0.8996 - val_accuracy: 0.7985 - val_loss: 0.8587\n",
            "Epoch 32/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7896 - loss: 0.9000 - val_accuracy: 0.7849 - val_loss: 0.8965\n",
            "Epoch 33/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7823 - loss: 0.8982 - val_accuracy: 0.8006 - val_loss: 0.8530\n",
            "Epoch 34/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7926 - loss: 0.8707 - val_accuracy: 0.7849 - val_loss: 0.9111\n",
            "Epoch 35/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7938 - loss: 0.8784 - val_accuracy: 0.7959 - val_loss: 0.9008\n",
            "Epoch 36/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7947 - loss: 0.8732 - val_accuracy: 0.7763 - val_loss: 0.9048\n",
            "Epoch 37/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7958 - loss: 0.8787 - val_accuracy: 0.7954 - val_loss: 0.8615\n",
            "Epoch 38/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7922 - loss: 0.8700 - val_accuracy: 0.7789 - val_loss: 0.8603\n",
            "Epoch 39/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7957 - loss: 0.8484 - val_accuracy: 0.7835 - val_loss: 0.8958\n",
            "Epoch 40/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7888 - loss: 0.8939 - val_accuracy: 0.7881 - val_loss: 0.8590\n",
            "Epoch 41/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.8006 - loss: 0.8685 - val_accuracy: 0.7549 - val_loss: 0.8689\n",
            "Epoch 42/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7853 - loss: 0.9017 - val_accuracy: 0.7388 - val_loss: 0.8881\n",
            "Epoch 43/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7898 - loss: 0.8889 - val_accuracy: 0.6692 - val_loss: 0.9237\n",
            "Epoch 44/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7855 - loss: 0.8850 - val_accuracy: 0.7900 - val_loss: 0.8633\n",
            "Epoch 45/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7912 - loss: 0.8891 - val_accuracy: 0.7671 - val_loss: 0.9034\n",
            "Epoch 46/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7919 - loss: 0.8675 - val_accuracy: 0.7566 - val_loss: 0.8923\n",
            "Epoch 47/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7901 - loss: 0.9049 - val_accuracy: 0.7657 - val_loss: 0.8978\n",
            "Epoch 48/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7825 - loss: 0.8953 - val_accuracy: 0.7821 - val_loss: 0.8539\n",
            "Epoch 49/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7941 - loss: 0.8361 - val_accuracy: 0.7794 - val_loss: 0.8515\n",
            "Epoch 50/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.8002 - loss: 0.8619 - val_accuracy: 0.7600 - val_loss: 0.8576\n",
            "\n",
            "Test Accuracy: 0.7600\n",
            "Test Loss: 0.6035\n",
            "\n",
            "Per-class Metrics:\n",
            "Wake: Precision=0.9940, Recall=0.8927, F1=0.9406\n",
            "N1: Precision=0.1657, Recall=0.3216, F1=0.2187\n",
            "N2: Precision=0.8444, Recall=0.2085, F1=0.3344\n",
            "N3: Precision=0.4797, Recall=0.9617, F1=0.6401\n",
            "REM: Precision=0.2537, Recall=0.7373, F1=0.3775\n"
          ]
        }
      ]
    }
  ]
}