{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnrQmJgUxMAombhijG7Uwt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameekshya1999/Sleep-Stage-Classification-Using-Deep-Learning-CNN-vs.-EEGNet-Attention-/blob/main/EEG_models_explore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyeni0Lkc3Z4",
        "outputId": "54ad9767-06c5-45d9-a098-504bbff4f06e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Collecting mne\n",
            "  Downloading mne-1.10.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Downloading mne-1.10.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy tensorflow keras mne urllib3 scikit-learn tqdm matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import mne\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import gc\n",
        "\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "mne.set_log_level('ERROR')\n",
        "\n",
        "NUM_SUBJECTS = 20\n",
        "NUM_NIGHTS = 2\n",
        "BASE_URL = \"https://physionet.org/files/sleep-edfx/1.0.0/\"\n",
        "TARGET_CHANNELS = ['EEG Fpz-Cz', 'EEG Pz-Oz']\n",
        "EPOCH_DURATION = 30\n",
        "BATCH_SIZE = 32  # Reduced from 128 to avoid OOM\n",
        "EPOCHS = 3\n",
        "SAMPLING_RATE = 50\n",
        "\n",
        "TELEMETRY_SUBJECTS = [2, 4, 5, 6, 7, 12, 13]\n",
        "POSSIBLE_HYPNO_LETTERS = 'CHJPUVAEMORW'  # Observed suffixes from dataset files\n",
        "\n",
        "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
        "\n",
        "def fetch_data(subject_id, night, record_type='PSG'):\n",
        "    try:\n",
        "        dataset_id = subject_id  # Fixed: no +1 to include subject 00 (SC400*)\n",
        "        folder = \"sleep-cassette\" if night == 1 else \"sleep-telemetry\"\n",
        "\n",
        "        if night == 1:\n",
        "            prefix = f\"SC4{dataset_id:02d}\"\n",
        "        else:\n",
        "            if subject_id not in TELEMETRY_SUBJECTS:\n",
        "                return None\n",
        "            telemetry_map = {2: 702, 4: 704, 5: 705, 6: 706, 7: 707, 12: 712, 13: 713}\n",
        "            prefix = f\"ST{telemetry_map.get(subject_id, 700 + dataset_id)}\"\n",
        "\n",
        "        os.makedirs(\"sleep_edf\", exist_ok=True)\n",
        "\n",
        "        if record_type == 'PSG':\n",
        "            base_suffix = \"E\" if night == 1 else \"J\"\n",
        "            file_name = f\"{prefix}{night if night == 1 else 2}{base_suffix}0-PSG.edf\"\n",
        "            url = f\"{BASE_URL}{folder}/{file_name}\"\n",
        "            local_file = os.path.join(\"sleep_edf\", file_name)\n",
        "            if os.path.exists(local_file):\n",
        "                return local_file\n",
        "            urllib.request.urlretrieve(url, local_file)\n",
        "            print(f\"Downloaded {file_name}\")\n",
        "            return local_file\n",
        "        else:  # Hypnogram\n",
        "            base_suffix = \"E\" if night == 1 else \"J\"\n",
        "            for letter in POSSIBLE_HYPNO_LETTERS:\n",
        "                hypno_suffix = base_suffix + letter\n",
        "                file_name = f\"{prefix}{night if night == 1 else 2}{hypno_suffix}-Hypnogram.edf\"\n",
        "                url = f\"{BASE_URL}{folder}/{file_name}\"\n",
        "                local_file = os.path.join(\"sleep_edf\", file_name)\n",
        "                if os.path.exists(local_file):\n",
        "                    return local_file\n",
        "                try:\n",
        "                    urllib.request.urlretrieve(url, local_file)\n",
        "                    print(f\"Downloaded {file_name}\")\n",
        "                    return local_file\n",
        "                except urllib.error.HTTPError as e:\n",
        "                    if e.code != 404:\n",
        "                        raise\n",
        "                    # Continue to next letter on 404\n",
        "            return None  # No matching suffix found\n",
        "    except urllib.error.HTTPError as e:\n",
        "        print(f\"HTTP Error {e.code} fetching {file_name if 'file_name' in locals() else 'file'}: {e.reason}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {file_name if 'file_name' in locals() else 'file'}: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_available_subjects():\n",
        "    available = []\n",
        "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = []\n",
        "        for subject_id in range(NUM_SUBJECTS):\n",
        "            for night in range(1, NUM_NIGHTS + 1):\n",
        "                futures.append((\n",
        "                    subject_id,\n",
        "                    night,\n",
        "                    executor.submit(\n",
        "                        lambda s, n: (\n",
        "                            fetch_data(s, n, 'PSG') is not None and\n",
        "                            fetch_data(s, n, 'Hypnogram') is not None\n",
        "                        ),\n",
        "                        subject_id, night\n",
        "                    )\n",
        "                ))\n",
        "\n",
        "        for subject_id, night, future in tqdm(futures, desc=\"Checking availability\"):\n",
        "            if future.result():\n",
        "                available.append((subject_id, night))\n",
        "    print(f\"Available subject-night pairs: {available}\")\n",
        "    return available\n",
        "\n",
        "def augment_data(X):\n",
        "    noise = np.random.normal(0, 0.01, X.shape)\n",
        "    shift = np.random.randint(-50, 50)\n",
        "    X_aug = np.roll(X + noise, shift, axis=1)\n",
        "    return X_aug\n",
        "\n",
        "def process_subject_night(subject_id, night):\n",
        "    try:\n",
        "        psg_file = fetch_data(subject_id, night, 'PSG')\n",
        "        hypno_file = fetch_data(subject_id, night, 'Hypnogram')\n",
        "        if psg_file is None or hypno_file is None:\n",
        "            print(f\"Skipping subject {subject_id}, night {night}: Missing files\")\n",
        "            return None, None\n",
        "\n",
        "        raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
        "        available_channels = [ch for ch in TARGET_CHANNELS if ch in raw.ch_names]\n",
        "        if not available_channels:\n",
        "            print(f\"No target channels for subject {subject_id}, night {night}\")\n",
        "            return None, None\n",
        "        raw.pick_channels(available_channels)\n",
        "\n",
        "        raw.load_data()\n",
        "        raw.filter(0.5, 40.0, l_trans_bandwidth=0.5, h_trans_bandwidth=10.0, verbose=False)\n",
        "        raw.resample(SAMPLING_RATE, npad=\"auto\")\n",
        "\n",
        "        events = mne.make_fixed_length_events(raw, id=1, duration=EPOCH_DURATION)\n",
        "        epochs_mne = mne.Epochs(raw, events, tmin=0, tmax=EPOCH_DURATION-1/raw.info['sfreq'],\n",
        "                                picks=available_channels, baseline=None, preload=True)\n",
        "        data = epochs_mne.get_data(units='uV')\n",
        "\n",
        "        annotations = mne.read_annotations(hypno_file)\n",
        "        labels = np.zeros(len(epochs_mne), dtype=int)\n",
        "        stage_map = {\n",
        "            'Sleep stage W': 0,\n",
        "            'Sleep stage 1': 1,\n",
        "            'Sleep stage 2': 2,\n",
        "            'Sleep stage 3': 3,\n",
        "            'Sleep stage 4': 3,\n",
        "            'Sleep stage R': 4\n",
        "        }\n",
        "\n",
        "        for annot in annotations:\n",
        "            onset = int(annot['onset'] / EPOCH_DURATION)\n",
        "            duration = int(annot['duration'] / EPOCH_DURATION)\n",
        "            stage = annot['description']\n",
        "            if stage in stage_map:\n",
        "                for i in range(max(0, onset), min(len(epochs_mne), onset + duration)):\n",
        "                    labels[i] = stage_map[stage]\n",
        "\n",
        "        data = (\n",
        "            (data - np.mean(data, axis=(1, 2), keepdims=True)) /\n",
        "            np.std(data, axis=(1, 2), keepdims=True)\n",
        "        )\n",
        "        X = data.transpose(0, 2, 1)\n",
        "        X_aug = augment_data(X)\n",
        "        X = np.concatenate([X, X_aug])\n",
        "        labels = np.concatenate([labels, labels])\n",
        "\n",
        "        del raw, epochs_mne, data\n",
        "        gc.collect()\n",
        "\n",
        "        print(f\"Processed subject {subject_id}, night {night}: {X.shape[0]} epochs\")\n",
        "        return X, labels\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing subject {subject_id}, night {night}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "class EEGDataGenerator(Sequence):\n",
        "    def __init__(self, X, y, batch_size, augment=True, class_weights=None):\n",
        "        self.X = X.astype(np.float32)\n",
        "        self.y = y.astype(np.int32)\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augment\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.batch_size\n",
        "        end = min(start + self.batch_size, len(self.X))\n",
        "        X_batch = self.X[start:end]\n",
        "        y_batch = self.y[start:end]\n",
        "\n",
        "        if self.augment:\n",
        "            X_batch = augment_data(X_batch).astype(np.float32)\n",
        "\n",
        "        sample_weights = np.ones_like(y_batch, dtype=np.float32)\n",
        "        if self.class_weights:\n",
        "            sample_weights = np.array([self.class_weights[label] for label in y_batch], dtype=np.float32)\n",
        "\n",
        "        return X_batch, y_batch, sample_weights\n",
        "\n",
        "class TemporalAttention(layers.Layer):\n",
        "    def __init__(self, heads=2, key_dim=16):  # Reduced heads and key_dim to save memory\n",
        "        super().__init__()\n",
        "        self.multi_head = layers.MultiHeadAttention(num_heads=heads, key_dim=key_dim)\n",
        "        self.norm = layers.LayerNormalization()\n",
        "        self.add = layers.Add()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn_output = self.multi_head(inputs, inputs)\n",
        "        out = self.add([inputs, attn_output])\n",
        "        return self.norm(out)\n",
        "\n",
        "def build_lstm_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.LSTM(128, return_sequences=True)(inputs)\n",
        "    x = layers.LSTM(64)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.LSTM(128, return_sequences=True)(inputs)\n",
        "    x = TemporalAttention()(x)\n",
        "    x = layers.LSTM(64)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_gru_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.GRU(128, return_sequences=True)(inputs)\n",
        "    x = layers.GRU(64)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_gru_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.GRU(128, return_sequences=True)(inputs)\n",
        "    x = TemporalAttention()(x)\n",
        "    x = layers.GRU(64)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv1D(64, 7, padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv1D(128, 5, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv1D(256, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Fully connected\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv1D(64, 7, padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv1D(128, 5, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv1D(256, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Temporal Attention\n",
        "    x = TemporalAttention()(x)\n",
        "\n",
        "    # Fully connected\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_eegnet_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv1D(64, 7, padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv1D(128, 7, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Output\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_eegnet_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv1D(64, 7, padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv1D(128, 7, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "\n",
        "    # Temporal Attention\n",
        "    x = TemporalAttention()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Output\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def plot_training_curves(history, model_name):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'{model_name} - Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{model_name} - Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'training_curves_{model_name}.png')\n",
        "    plt.close()\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\n{model_name} - Test Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"{model_name} - Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    y_pred = model.predict(X_test, verbose=0)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_classes, average=None)\n",
        "    stage_names = ['Wake', 'N1', 'N2', 'N3', 'REM']\n",
        "    print(f\"\\n{model_name} - Per-class Metrics:\")\n",
        "    for i, stage in enumerate(stage_names):\n",
        "        print(f\"{stage}: Precision={precision[i]:.4f}, Recall={recall[i]:.4f}, F1={f1[i]:.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=stage_names, yticklabels=stage_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.savefig(f'confusion_matrix_{model_name}.png')\n",
        "    plt.close()\n",
        "\n",
        "    return test_acc\n",
        "\n",
        "def data_generator(available, batch_size=2000):\n",
        "    for subject_id, night in available:\n",
        "        X, y = process_subject_night(subject_id, night)\n",
        "        if X is None or y is None:\n",
        "            continue\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            yield X[i:i+batch_size], y[i:i+batch_size]\n",
        "        del X, y\n",
        "        gc.collect()\n",
        "\n",
        "def run_pipeline():\n",
        "    available = get_available_subjects()\n",
        "    if not available:\n",
        "        return\n",
        "\n",
        "    X_train, y_train, X_test, y_test = [], [], [], []\n",
        "    for X_batch, y_batch in tqdm(data_generator(available), desc=\"Processing data\"):\n",
        "        if X_batch is None or y_batch is None:\n",
        "            continue\n",
        "        class_counts = np.bincount(y_batch)\n",
        "        stratify = y_batch if min(class_counts[class_counts > 0]) >= 2 else None\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X_batch, y_batch, test_size=0.2, stratify=stratify, random_state=42)\n",
        "        X_train.append(X_tr); y_train.append(y_tr)\n",
        "        X_test.append(X_te); y_test.append(y_te)\n",
        "        del X_batch, y_batch\n",
        "        gc.collect()\n",
        "\n",
        "    if not X_train:\n",
        "        return\n",
        "\n",
        "    X_train = np.concatenate(X_train)\n",
        "    y_train = np.concatenate(y_train)\n",
        "    X_test = np.concatenate(X_test)\n",
        "    y_test = np.concatenate(y_test)\n",
        "\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "    train_generator = EEGDataGenerator(X_train, y_train, BATCH_SIZE, augment=True, class_weights=class_weight_dict)\n",
        "    val_generator = EEGDataGenerator(X_test, y_test, BATCH_SIZE, augment=False, class_weights=class_weight_dict)\n",
        "\n",
        "    models_dict = {\n",
        "        \"LSTM\": build_lstm_model,\n",
        "        \"LSTM_Attention\": build_lstm_attention_model,\n",
        "        \"GRU\": build_gru_model,\n",
        "        \"GRU_Attention\": build_gru_attention_model,\n",
        "        \"CNN\": build_cnn_model,\n",
        "        \"CNN_Attention\": build_cnn_attention_model,\n",
        "        \"EEGNet\": build_eegnet_model,\n",
        "        \"EEGNet_Attention\": build_eegnet_attention_model\n",
        "    }\n",
        "\n",
        "    accuracies = {}\n",
        "\n",
        "    for name, build_func in models_dict.items():\n",
        "        print(f\"\\nTraining {name} model...\")\n",
        "        model = build_func(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
        "        history = model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS, verbose=1)\n",
        "        plot_training_curves(history, name)\n",
        "        acc = evaluate_model(model, X_test, y_test, name)\n",
        "        accuracies[name] = acc\n",
        "\n",
        "    # Compare accuracies\n",
        "    best_model = max(accuracies, key=accuracies.get)\n",
        "    print(\"\\nModel Comparison:\")\n",
        "    for name, acc in sorted(accuracies.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"{name}: {acc:.4f}\")\n",
        "    print(f\"\\nHighest accuracy model: {best_model} with {accuracies[best_model]:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drzuxZ62g9L5",
        "outputId": "6e26567e-1695-4564-bc17-3328a3c126cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn version: 1.6.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:   0%|          | 0/40 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded ST7042J0-PSG.edf\n",
            "Downloaded ST7042JO-Hypnogram.edf\n",
            "Downloaded ST7062J0-PSG.edf\n",
            "Downloaded ST7062JR-Hypnogram.edf\n",
            "Downloaded SC4051E0-PSG.edf\n",
            "Downloaded SC4051EC-Hypnogram.edf\n",
            "Downloaded ST7022J0-PSG.edf\n",
            "Downloaded ST7022JM-Hypnogram.edf\n",
            "Downloaded ST7052J0-PSG.edf\n",
            "Downloaded ST7052JA-Hypnogram.edf\n",
            "Downloaded SC4011E0-PSG.edf\n",
            "Downloaded SC4011EH-Hypnogram.edf\n",
            "Downloaded ST7072J0-PSG.edf\n",
            "Downloaded ST7072JA-Hypnogram.edf\n",
            "Downloaded SC4041E0-PSG.edf\n",
            "Downloaded SC4041EC-Hypnogram.edf\n",
            "Downloaded SC4001E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:   2%|▎         | 1/40 [07:38<4:58:17, 458.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4001EC-Hypnogram.edf\n",
            "Downloaded SC4061E0-PSG.edf\n",
            "Downloaded SC4061EC-Hypnogram.edf\n",
            "Downloaded SC4021E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  12%|█▎        | 5/40 [07:50<41:20, 70.88s/it]   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4021EH-Hypnogram.edf\n",
            "Downloaded SC4031E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  18%|█▊        | 7/40 [07:52<24:26, 44.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4031EC-Hypnogram.edf\n",
            "Downloaded SC4071E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  38%|███▊      | 15/40 [11:02<12:36, 30.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4071EC-Hypnogram.edf\n",
            "Downloaded ST7132J0-PSG.edf\n",
            "Downloaded ST7132JR-Hypnogram.edf\n",
            "Downloaded ST7122J0-PSG.edf\n",
            "Downloaded ST7122JE-Hypnogram.edf\n",
            "Downloaded SC4091E0-PSG.edf\n",
            "Downloaded SC4091EC-Hypnogram.edf\n",
            "Downloaded SC4081E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  42%|████▎     | 17/40 [13:51<15:40, 40.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4081EC-Hypnogram.edf\n",
            "Downloaded SC4101E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  52%|█████▎    | 21/40 [17:13<14:02, 44.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4101EC-Hypnogram.edf\n",
            "Downloaded SC4111E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  57%|█████▊    | 23/40 [17:37<10:42, 37.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4111EC-Hypnogram.edf\n",
            "Downloaded SC4121E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  62%|██████▎   | 25/40 [18:33<08:52, 35.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4121EC-Hypnogram.edf\n",
            "Downloaded SC4141E0-PSG.edf\n",
            "Downloaded SC4141EU-Hypnogram.edf\n",
            "Downloaded SC4131E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  68%|██████▊   | 27/40 [18:50<06:16, 28.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4131EC-Hypnogram.edf\n",
            "Downloaded SC4151E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  78%|███████▊  | 31/40 [20:05<03:43, 24.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4151EC-Hypnogram.edf\n",
            "Downloaded SC4161E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  82%|████████▎ | 33/40 [20:58<02:56, 25.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4161EC-Hypnogram.edf\n",
            "Downloaded SC4171E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  88%|████████▊ | 35/40 [21:10<01:42, 20.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4171EU-Hypnogram.edf\n",
            "Downloaded SC4181E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rChecking availability:  92%|█████████▎| 37/40 [21:13<00:46, 15.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4181EC-Hypnogram.edf\n",
            "Downloaded SC4191E0-PSG.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking availability: 100%|██████████| 40/40 [21:18<00:00, 31.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded SC4191EP-Hypnogram.edf\n",
            "Available subject-night pairs: [(0, 1), (1, 1), (2, 1), (2, 2), (3, 1), (4, 1), (4, 2), (5, 1), (5, 2), (6, 1), (6, 2), (7, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (12, 2), (13, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing data: 0it [00:00, ?it/s]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 0, night 1: 5300 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 3it [00:05,  1.26s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 1, night 1: 5604 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 6it [00:11,  1.37s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 2, night 1: 5608 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 9it [00:16,  1.35s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 2, night 2: 2050 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 11it [00:21,  1.66s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 3, night 1: 5640 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 14it [00:27,  1.46s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 4, night 1: 5140 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 17it [00:30,  1.10s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 4, night 2: 2314 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 19it [00:36,  1.73s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 5, night 1: 5444 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 22it [00:40,  1.22s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 5, night 2: 2188 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 24it [00:44,  1.49s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 6, night 1: 5540 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 27it [00:49,  1.22s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 6, night 2: 2184 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 29it [00:54,  1.75s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 7, night 1: 5620 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 32it [01:00,  1.49s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 7, night 2: 1830 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing data: 33it [01:03,  2.15s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 8, night 1: 5592 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 36it [01:07,  1.38s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 9, night 1: 5464 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 39it [01:12,  1.16s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 10, night 1: 5440 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 42it [01:16,  1.04s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 11, night 1: 5284 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 45it [01:19,  1.02it/s]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 12, night 1: 5572 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 48it [01:24,  1.04s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 12, night 2: 2022 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 50it [01:28,  1.45s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 13, night 1: 5628 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 53it [01:33,  1.30s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 13, night 2: 1798 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing data: 54it [01:38,  2.46s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 14, night 1: 5512 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 57it [01:44,  1.67s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 15, night 1: 5240 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 60it [01:48,  1.27s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 16, night 1: 5252 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 63it [01:52,  1.05s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 17, night 1: 5484 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 66it [01:57,  1.19s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 18, night 1: 5512 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 69it [02:02,  1.12s/it]/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n",
            "/tmp/ipython-input-2-3307882880.py:127: RuntimeWarning: Highpass cutoff frequency 16.0 is greater than lowpass cutoff frequency 0.7, setting values to 0 and Nyquist.\n",
            "  raw = mne.io.read_raw_edf(psg_file, preload=False, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed subject 19, night 1: 5548 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing data: 72it [02:07,  1.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTM model...\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.3917 - loss: 1.5673"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 87ms/step - accuracy: 0.3917 - loss: 1.5673 - val_accuracy: 0.5173 - val_loss: 1.6115\n",
            "Epoch 2/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 92ms/step - accuracy: 0.4728 - loss: 1.5461 - val_accuracy: 0.6911 - val_loss: 1.3262\n",
            "Epoch 3/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 88ms/step - accuracy: 0.4905 - loss: 1.5179 - val_accuracy: 0.7180 - val_loss: 1.1409\n",
            "\n",
            "LSTM - Test Accuracy: 0.7180\n",
            "LSTM - Test Loss: 0.7990\n",
            "\n",
            "LSTM - Per-class Metrics:\n",
            "Wake: Precision=0.9514, Recall=0.9285, F1=0.9398\n",
            "N1: Precision=0.0920, Recall=0.1961, F1=0.1252\n",
            "N2: Precision=0.6228, Recall=0.2825, F1=0.3887\n",
            "N3: Precision=0.3562, Recall=0.7072, F1=0.4738\n",
            "REM: Precision=0.2741, Recall=0.3681, F1=0.3142\n",
            "\n",
            "Training LSTM_Attention model...\n",
            "Epoch 1/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 166ms/step - accuracy: 0.6010 - loss: 1.1757 - val_accuracy: 0.7862 - val_loss: 0.7544\n",
            "Epoch 2/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 165ms/step - accuracy: 0.7817 - loss: 0.7913 - val_accuracy: 0.7942 - val_loss: 0.7331\n",
            "Epoch 3/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 166ms/step - accuracy: 0.8033 - loss: 0.7437 - val_accuracy: 0.8046 - val_loss: 0.6931\n",
            "\n",
            "LSTM_Attention - Test Accuracy: 0.8046\n",
            "LSTM_Attention - Test Loss: 0.4620\n",
            "\n",
            "LSTM_Attention - Per-class Metrics:\n",
            "Wake: Precision=0.9971, Recall=0.9280, F1=0.9613\n",
            "N1: Precision=0.1401, Recall=0.7673, F1=0.2369\n",
            "N2: Precision=0.8546, Recall=0.6180, F1=0.7173\n",
            "N3: Precision=0.7299, Recall=0.8673, F1=0.7927\n",
            "REM: Precision=0.5776, Recall=0.2840, F1=0.3807\n",
            "\n",
            "Training GRU model...\n",
            "Epoch 1/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 94ms/step - accuracy: 0.4692 - loss: 1.4691 - val_accuracy: 0.7843 - val_loss: 0.8263\n",
            "Epoch 2/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 90ms/step - accuracy: 0.7735 - loss: 0.8066 - val_accuracy: 0.8202 - val_loss: 0.7126\n",
            "Epoch 3/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 88ms/step - accuracy: 0.8162 - loss: 0.6943 - val_accuracy: 0.8310 - val_loss: 0.6493\n",
            "\n",
            "GRU - Test Accuracy: 0.8310\n",
            "GRU - Test Loss: 0.4196\n",
            "\n",
            "GRU - Per-class Metrics:\n",
            "Wake: Precision=0.9984, Recall=0.9202, F1=0.9577\n",
            "N1: Precision=0.1616, Recall=0.7560, F1=0.2663\n",
            "N2: Precision=0.8145, Recall=0.7683, F1=0.7907\n",
            "N3: Precision=0.7852, Recall=0.8860, F1=0.8326\n",
            "REM: Precision=0.8211, Recall=0.2869, F1=0.4252\n",
            "\n",
            "Training GRU_Attention model...\n",
            "Epoch 1/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 165ms/step - accuracy: 0.5942 - loss: 1.2288 - val_accuracy: 0.8096 - val_loss: 0.7472\n",
            "Epoch 2/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 165ms/step - accuracy: 0.7951 - loss: 0.7441 - val_accuracy: 0.8012 - val_loss: 0.6449\n",
            "Epoch 3/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 165ms/step - accuracy: 0.8299 - loss: 0.6695 - val_accuracy: 0.8206 - val_loss: 0.6594\n",
            "\n",
            "GRU_Attention - Test Accuracy: 0.8206\n",
            "GRU_Attention - Test Loss: 0.4484\n",
            "\n",
            "GRU_Attention - Per-class Metrics:\n",
            "Wake: Precision=0.9989, Recall=0.9285, F1=0.9624\n",
            "N1: Precision=0.1536, Recall=0.8519, F1=0.2602\n",
            "N2: Precision=0.8597, Recall=0.6468, F1=0.7382\n",
            "N3: Precision=0.8329, Recall=0.8324, F1=0.8327\n",
            "REM: Precision=0.7274, Recall=0.4031, F1=0.5187\n",
            "\n",
            "Training CNN model...\n",
            "Epoch 1/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 12ms/step - accuracy: 0.5479 - loss: 1.5621 - val_accuracy: 0.7883 - val_loss: 0.6942\n",
            "Epoch 2/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10ms/step - accuracy: 0.7482 - loss: 0.8720 - val_accuracy: 0.7919 - val_loss: 0.6669\n",
            "Epoch 3/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10ms/step - accuracy: 0.8129 - loss: 0.6967 - val_accuracy: 0.7984 - val_loss: 0.6560\n",
            "\n",
            "CNN - Test Accuracy: 0.7984\n",
            "CNN - Test Loss: 0.5354\n",
            "\n",
            "CNN - Per-class Metrics:\n",
            "Wake: Precision=0.9998, Recall=0.7841, F1=0.8789\n",
            "N1: Precision=0.1429, Recall=0.4697, F1=0.2191\n",
            "N2: Precision=0.8137, Recall=0.8773, F1=0.8443\n",
            "N3: Precision=0.8104, Recall=0.8312, F1=0.8207\n",
            "REM: Precision=0.4917, Recall=0.8031, F1=0.6100\n",
            "\n",
            "Training CNN_Attention model...\n",
            "Epoch 1/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 14ms/step - accuracy: 0.5860 - loss: 1.4424 - val_accuracy: 0.8199 - val_loss: 0.7438\n",
            "Epoch 2/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.7818 - loss: 0.8302 - val_accuracy: 0.7987 - val_loss: 0.6342\n",
            "Epoch 3/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 11ms/step - accuracy: 0.8415 - loss: 0.6769 - val_accuracy: 0.8437 - val_loss: 0.6036\n",
            "\n",
            "CNN_Attention - Test Accuracy: 0.8437\n",
            "CNN_Attention - Test Loss: 0.4186\n",
            "\n",
            "CNN_Attention - Per-class Metrics:\n",
            "Wake: Precision=0.9991, Recall=0.8801, F1=0.9358\n",
            "N1: Precision=0.2020, Recall=0.6530, F1=0.3086\n",
            "N2: Precision=0.8375, Recall=0.8299, F1=0.8337\n",
            "N3: Precision=0.6839, Recall=0.9209, F1=0.7849\n",
            "REM: Precision=0.6912, Recall=0.6058, F1=0.6457\n",
            "\n",
            "Training EEGNet model...\n",
            "Epoch 1/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.7983 - loss: 0.7039 - val_accuracy: 0.8691 - val_loss: 0.4946\n",
            "Epoch 2/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.8827 - loss: 0.4720 - val_accuracy: 0.8746 - val_loss: 0.4529\n",
            "Epoch 3/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - accuracy: 0.8996 - loss: 0.4231 - val_accuracy: 0.8730 - val_loss: 0.4793\n",
            "\n",
            "EEGNet - Test Accuracy: 0.8730\n",
            "EEGNet - Test Loss: 0.3410\n",
            "\n",
            "EEGNet - Per-class Metrics:\n",
            "Wake: Precision=0.9968, Recall=0.9363, F1=0.9656\n",
            "N1: Precision=0.2817, Recall=0.8054, F1=0.4174\n",
            "N2: Precision=0.9272, Recall=0.7530, F1=0.8311\n",
            "N3: Precision=0.6648, Recall=0.9477, F1=0.7814\n",
            "REM: Precision=0.6933, Recall=0.6486, F1=0.6702\n",
            "\n",
            "Training EEGNet_Attention model...\n",
            "Epoch 1/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 12ms/step - accuracy: 0.8032 - loss: 0.6852 - val_accuracy: 0.8618 - val_loss: 0.5051\n",
            "Epoch 2/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 9ms/step - accuracy: 0.8774 - loss: 0.4788 - val_accuracy: 0.8911 - val_loss: 0.4999\n",
            "Epoch 3/3\n",
            "\u001b[1m3096/3096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 9ms/step - accuracy: 0.8989 - loss: 0.4068 - val_accuracy: 0.8917 - val_loss: 0.4742\n",
            "\n",
            "EEGNet_Attention - Test Accuracy: 0.8917\n",
            "EEGNet_Attention - Test Loss: 0.3062\n",
            "\n",
            "EEGNet_Attention - Per-class Metrics:\n",
            "Wake: Precision=0.9981, Recall=0.9474, F1=0.9721\n",
            "N1: Precision=0.3080, Recall=0.6460, F1=0.4171\n",
            "N2: Precision=0.9246, Recall=0.7742, F1=0.8427\n",
            "N3: Precision=0.7743, Recall=0.8829, F1=0.8250\n",
            "REM: Precision=0.6569, Recall=0.8469, F1=0.7399\n",
            "\n",
            "Model Comparison:\n",
            "EEGNet_Attention: 0.8917\n",
            "EEGNet: 0.8730\n",
            "CNN_Attention: 0.8437\n",
            "GRU: 0.8310\n",
            "GRU_Attention: 0.8206\n",
            "LSTM_Attention: 0.8046\n",
            "CNN: 0.7984\n",
            "LSTM: 0.7180\n",
            "\n",
            "Highest accuracy model: EEGNet_Attention with 0.8917\n"
          ]
        }
      ]
    }
  ]
}